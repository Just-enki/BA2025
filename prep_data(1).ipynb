{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0409450-3b84-4ec4-bbc8-bc5a53b9abbd",
   "metadata": {},
   "source": [
    "# run growth.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e6ed5-f85d-45e0-a749-aed0106b9da5",
   "metadata": {},
   "source": [
    "## generates \"ndvi_all_results_growth.csv\" (ndvi_3.1 + growth rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d05933-b18b-486c-b87a-02a215f78d49",
   "metadata": {},
   "source": [
    "# get image brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272c8d28-dada-4e2d-a0ac-6e3c0b2355ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Directory: ba_1_1_organized (Saving as Camera: ba_3) ---\n",
      "  Processing Date: Sep_10\n",
      "  Processing Date: Sep_14\n",
      "  Processing Date: Sep_12\n",
      "  Processing Date: Sep_13\n",
      "  Processing Date: Sep_04\n",
      "    No image files found in ba_1_1_organized/Sep_04\n",
      "  Processing Date: Sep_07\n",
      "  Processing Date: Sep_11\n",
      "  Processing Date: Sep_09\n",
      "  Processing Date: Sep_05\n",
      "  Processing Date: Sep_08\n",
      "  Processing Date: Sep_06\n",
      "\n",
      "--- Processing Directory: ba_1_organized (Saving as Camera: ba_1) ---\n",
      "  Processing Date: Aug_31\n",
      "  Processing Date: Sep_03\n",
      "  Processing Date: Aug_30\n",
      "  Processing Date: Sep_04\n",
      "  Processing Date: Aug_27\n",
      "  Processing Date: Aug_29\n",
      "  Processing Date: Sep_01\n",
      "  Processing Date: Sep_02\n",
      "  Processing Date: Aug_26\n",
      "  Processing Date: Aug_28\n",
      "\n",
      "--- Processing Directory: ba_2_2_organized (Saving as Camera: ba_4) ---\n",
      "  Processing Date: Sep_10\n",
      "  Processing Date: Sep_14\n",
      "  Processing Date: Sep_12\n",
      "  Processing Date: Sep_13\n",
      "  Processing Date: Sep_04\n",
      "    No image files found in ba_2_2_organized/Sep_04\n",
      "  Processing Date: Sep_07\n",
      "  Processing Date: Sep_11\n",
      "  Processing Date: Sep_09\n",
      "  Processing Date: Sep_05\n",
      "  Processing Date: Sep_08\n",
      "  Processing Date: Sep_06\n",
      "\n",
      "--- Processing Directory: ba_2_organized (Saving as Camera: ba_2) ---\n",
      "  Processing Date: Aug_31\n",
      "  Processing Date: Sep_03\n",
      "  Processing Date: Aug_30\n",
      "  Processing Date: Sep_04\n",
      "  Processing Date: Aug_27\n",
      "  Processing Date: Aug_29\n",
      "  Processing Date: Sep_01\n",
      "  Processing Date: Sep_02\n",
      "  Processing Date: Aug_26\n",
      "  Processing Date: Aug_28\n",
      "\n",
      "Saved results to image_brightness_and_metadata.csv\n",
      "\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def get_image_brightness_cv2(image_path):\n",
    "    try:\n",
    "        img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error: Could not read the image at {image_path}.\")\n",
    "            return None\n",
    "        \n",
    "        # get mean\n",
    "        brightness = np.mean(img)\n",
    "        return brightness\n",
    "    except Exception as e:\n",
    "        print(f\" error with {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_datetime_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Extract datetime from filename with format DD_MM_HH_MM_ndvi.jpg\n",
    "    Also handles variations like DD_MM_HH_MM.jpg or DD_MM_HH_MM_ndvi.jpg\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove file extension and split by underscores\n",
    "        name_without_ext = os.path.splitext(filename)[0]\n",
    "        parts = name_without_ext.split('_')\n",
    "        \n",
    "        # Handle different filename formats\n",
    "        if len(parts) >= 4:\n",
    "            # Check if the last part is 'ndvi' and remove it\n",
    "            if parts[-1].lower() == 'ndvi':\n",
    "                parts = parts[:-1]\n",
    "            \n",
    "            if len(parts) >= 4:\n",
    "                day = int(parts[0])\n",
    "                month = int(parts[1])\n",
    "                hour = int(parts[2])\n",
    "                minute = int(parts[3])\n",
    "                \n",
    "                # Create a datetime object (using current year since it's not in filename)\n",
    "                dt = datetime(datetime.now().year, month, day, hour, minute)\n",
    "                return dt\n",
    "    except (ValueError, IndexError):\n",
    "        pass\n",
    "    # Return a very old date if parsing fails, so these files appear first\n",
    "    return datetime(1900, 1, 1)\n",
    "\n",
    "def batch_process_all_directories(base_directory=\".\"):\n",
    "    \"\"\"\n",
    "    Process all subdirectories matching the pattern 'ba_*_organized',\n",
    "    extracting brightness and metadata for each image.\n",
    "    \"\"\"\n",
    "    base_dir = Path(base_directory)\n",
    "    all_results = []\n",
    "\n",
    "    # Find all matching directories dynamically\n",
    "    camera_directories = sorted(base_dir.glob(\"ba_*_organized\"))\n",
    "\n",
    "    for cam_dir in camera_directories:\n",
    "        if not cam_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        # Extract the original camera name from the directory\n",
    "        parts = cam_dir.name.split('_')\n",
    "        original_camera_name = '_'.join(parts[:-1])\n",
    "\n",
    "        # --- CHANGE: Remap specific camera names as requested ---\n",
    "        # This block checks the original name and reassigns it for the CSV file.\n",
    "        if original_camera_name == 'ba_1_1':\n",
    "            camera_name_to_save = 'ba_3'\n",
    "        elif original_camera_name == 'ba_2_2':\n",
    "            camera_name_to_save = 'ba_4'\n",
    "        else:\n",
    "            camera_name_to_save = original_camera_name\n",
    "\n",
    "        print(f\"\\n--- Processing Directory: {cam_dir.name} (Saving as Camera: {camera_name_to_save}) ---\")\n",
    "\n",
    "        # Process each date subdirectory\n",
    "        for date_dir in cam_dir.iterdir():\n",
    "            if date_dir.is_dir() and date_dir.name in [\n",
    "                'Aug_26','Aug_27','Aug_28','Aug_29','Aug_30','Aug_31',\n",
    "                'Sep_01','Sep_02','Sep_03','Sep_04','Sep_05','Sep_06',\n",
    "                'Sep_07','Sep_08','Sep_09','Sep_10','Sep_11','Sep_12','Sep_13','Sep_14'\n",
    "            ]:\n",
    "                print(f\"  Processing Date: {date_dir.name}\")\n",
    "\n",
    "                try:\n",
    "                    # Find all image files in the directory\n",
    "                    image_files = [\n",
    "                        f for f in date_dir.iterdir() \n",
    "                        if f.suffix.lower() in ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "                    ]\n",
    "\n",
    "                    if not image_files:\n",
    "                        print(f\"    No image files found in {date_dir}\")\n",
    "                        continue\n",
    "\n",
    "                    for image_path in image_files:\n",
    "                        brightness_value = get_image_brightness_cv2(image_path)\n",
    "                        parsed_datetime = parse_datetime_from_filename(image_path.name)\n",
    "                        \n",
    "                        if brightness_value is not None:\n",
    "                            all_results.append({\n",
    "                                'full_path': str(image_path),\n",
    "                                'camera': camera_name_to_save, # Use the remapped name\n",
    "                                'date_dir': date_dir.name,\n",
    "                                'image': image_path.name,\n",
    "                                'brightness': brightness_value,\n",
    "                                'datetime': parsed_datetime\n",
    "                            })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {date_dir}: {e}\")\n",
    "\n",
    "    # Create DataFrame and save results\n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        # Sort the DataFrame by camera and datetime\n",
    "        df.sort_values(by=['camera', 'datetime'], inplace=True)\n",
    "        output_csv = base_dir / \"image_brightness_and_metadata.csv\"\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"\\nSaved results to {output_csv}\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No results to save\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can specify the base directory here.\n",
    "    # For example, use \".\" to start from the current directory.\n",
    "    df_results = batch_process_all_directories(base_directory=\".\")\n",
    "    print(\"\\nProcessing complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef943fb-4937-4ba4-a88e-b684fe6de69f",
   "metadata": {},
   "source": [
    "# merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24641543-3d90-4621-a2d1-7bd997be34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_ndvi = pd.read_csv('ndvi_all_results_growth.csv')\n",
    "df_light = pd.read_csv('image_brightness_and_metadata.csv')\n",
    "\n",
    "df_light = df_light.drop('datetime', axis=1)\n",
    "\n",
    "df_merged = pd.merge(df_ndvi, df_light, on=['camera', 'image'])\n",
    "\n",
    "df_merged = df_merged.drop('date_dir', axis=1)\n",
    "\n",
    "df_merged = df_merged.drop('full_path', axis=1)\n",
    "\n",
    "df_merged.to_csv('ndvi_light_growth_b.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15c445-03a2-4541-9388-dde5e4688975",
   "metadata": {},
   "source": [
    "# filter datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e8ed31-b5f1-47d9-8780-fc6b7bb93602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 6494 total records from ndvi_light_growth_b.csv\n",
      "After applying threshold >= 0.0, 5205 records remain.\n",
      "Saved 5205 records to ndvi_light_growth_filtered_all_b.csv. Filtering was applied to all cameras.\n",
      "\n",
      "--- First 5 rows of the final, filtered dataset ---\n",
      "       mean    median       std       min       max  growth_metric  \\\n",
      "0  0.890559  0.999999  0.312189  0.000000  0.999999       324164.0   \n",
      "1  0.416240  0.000000  0.497336 -0.999995  0.999999       131599.0   \n",
      "2  0.835001  0.999999  0.371177  0.000000  0.999999       303941.0   \n",
      "3  0.347919  0.000000  0.591006 -0.999991  0.999999       129489.0   \n",
      "4  0.831821  0.999999  0.374021  0.000000  0.999999       302784.0   \n",
      "\n",
      "             image camera date_folder            datetime  brightness  \n",
      "0  26_08_16_37.jpg   ba_2      Aug_26 2025-08-26 16:37:00   33.952615  \n",
      "1  26_08_16_37.jpg   ba_1      Aug_26 2025-08-26 16:37:00    8.686000  \n",
      "2  26_08_16_40.jpg   ba_2      Aug_26 2025-08-26 16:40:00   31.128231  \n",
      "3  26_08_16_40.jpg   ba_1      Aug_26 2025-08-26 16:40:00    7.874167  \n",
      "4  26_08_16_45.jpg   ba_2      Aug_26 2025-08-26 16:45:00   33.120034  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_all_cameras(input_filename=\"ndvi_light_growth_b.csv\",\n",
    "                         output_filename=\"ndvi_light_growth_filtered_all_b.csv\",\n",
    "                         threshold=0.0):\n",
    "    \"\"\"\n",
    "    Loads a dataset and filters ALL records based on a mean NDVI threshold.\n",
    "    \"\"\"\n",
    "    # 1. Load the entire dataset from the input file\n",
    "    try:\n",
    "        df = pd.read_csv(input_filename)\n",
    "        print(f\"Read {len(df)} total records from {input_filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_filename}' not found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 2. Apply the threshold filter to the entire DataFrame\n",
    "    df_filtered = df[df['mean'] >= threshold].copy()\n",
    "    print(f\"After applying threshold >= {threshold}, {len(df_filtered)} records remain.\")\n",
    "\n",
    "    # 3. Optional but good practice: sort the final dataframe\n",
    "    if 'datetime' in df_filtered.columns:\n",
    "        df_filtered['datetime'] = pd.to_datetime(df_filtered['datetime'])\n",
    "        df_filtered = df_filtered.sort_values('datetime')\n",
    "\n",
    "    # 4. Save the newly filtered dataframe to the output file\n",
    "    df_filtered.to_csv(output_filename, index=False)\n",
    "    print(f\"Saved {len(df_filtered)} records to {output_filename}. Filtering was applied to all cameras.\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # This will run the function with the default settings\n",
    "    # It will filter the entire dataset, keeping rows where the 'mean' NDVI is >= 0.0\n",
    "    filtered_data = filter_all_cameras()\n",
    "    \n",
    "    print(\"\\n--- First 5 rows of the final, filtered dataset ---\")\n",
    "    print(filtered_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be834a01-e645-49be-932d-c3cef46e4550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 outliers removed. Rolling Z-score threshold: 2.\n",
      "5076 data points remaining.\n",
      "                         mean    median       std       min       max  \\\n",
      "datetime                                                                \n",
      "2025-08-26 16:37:00  0.890559  0.999999  0.312189  0.000000  0.999999   \n",
      "2025-08-26 16:37:00  0.416240  0.000000  0.497336 -0.999995  0.999999   \n",
      "2025-08-26 16:40:00  0.835001  0.999999  0.371177  0.000000  0.999999   \n",
      "2025-08-26 16:40:00  0.347919  0.000000  0.591006 -0.999991  0.999999   \n",
      "2025-08-26 16:45:00  0.831821  0.999999  0.374021  0.000000  0.999999   \n",
      "\n",
      "                     growth_metric            image camera date_folder  \\\n",
      "datetime                                                                 \n",
      "2025-08-26 16:37:00       324164.0  26_08_16_37.jpg   ba_2      Aug_26   \n",
      "2025-08-26 16:37:00       131599.0  26_08_16_37.jpg   ba_1      Aug_26   \n",
      "2025-08-26 16:40:00       303941.0  26_08_16_40.jpg   ba_2      Aug_26   \n",
      "2025-08-26 16:40:00       129489.0  26_08_16_40.jpg   ba_1      Aug_26   \n",
      "2025-08-26 16:45:00       302784.0  26_08_16_45.jpg   ba_2      Aug_26   \n",
      "\n",
      "                     brightness  \n",
      "datetime                         \n",
      "2025-08-26 16:37:00   33.952615  \n",
      "2025-08-26 16:37:00    8.686000  \n",
      "2025-08-26 16:40:00   31.128231  \n",
      "2025-08-26 16:40:00    7.874167  \n",
      "2025-08-26 16:45:00   33.120034  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_by_rolling_zscore(input_filename=\"ndvi_light_growth_filtered_all_b.csv\",\n",
    "                               output=\"ndvi_light_growth_f_b.csv\",\n",
    "                               column_to_check='mean',\n",
    "                               window_size=6, # The number of data points in the moving window\n",
    "                               threshold=2):\n",
    "    \n",
    "    df = pd.read_csv(input_filename)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime').set_index('datetime')\n",
    "\n",
    "    # Calculate rolling mean and std dev\n",
    "    # The window_size is crucial - you may need to tune it\n",
    "    df['rolling_mean'] = df[column_to_check].rolling(window=window_size, min_periods=1).mean()\n",
    "    df['rolling_std'] = df[column_to_check].rolling(window=window_size, min_periods=1).std()\n",
    "\n",
    "    # Calculate the z-score based on the rolling window\n",
    "    # We fill NaNs in std dev with a small number to avoid division by zero\n",
    "    df['z_score'] = (df[column_to_check] - df['rolling_mean']) / df['rolling_std'].fillna(1e-9)\n",
    "\n",
    "    # Filter out the outliers\n",
    "    original_count = len(df)\n",
    "    filtered_df = df[df['z_score'].abs() <= threshold].copy()\n",
    "    \n",
    "    # Drop helper columns\n",
    "    filtered_df = filtered_df.drop(columns=['rolling_mean', 'rolling_std', 'z_score'])\n",
    "    \n",
    "    print(f\"{original_count - len(filtered_df)} outliers removed. Rolling Z-score threshold: {threshold}.\")\n",
    "    print(f\"{len(filtered_df)} data points remaining.\")\n",
    "\n",
    "    filtered_df.reset_index().to_csv(output, index=False)\n",
    "    return filtered_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cleaned_data = filter_by_rolling_zscore()\n",
    "    if cleaned_data is not None:\n",
    "        print(cleaned_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edbbbe6-c55b-4938-ac3a-8803cfc02e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
